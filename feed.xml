<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ja"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://keisuke-yanagisawa.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://keisuke-yanagisawa.github.io/" rel="alternate" type="text/html" hreflang="ja" /><updated>2022-02-14T14:31:09+09:00</updated><id>https://keisuke-yanagisawa.github.io/feed.xml</id><title type="html">柳澤 渓甫 | Keisuke Yanagisawa</title><subtitle>An assistant professor in Tokyo Tech.</subtitle><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><entry><title type="html">検証誤差と汎化誤差</title><link href="https://keisuke-yanagisawa.github.io/202202/validation_and_generalization_error/" rel="alternate" type="text/html" title="検証誤差と汎化誤差" /><published>2022-02-13T00:00:00+09:00</published><updated>2022-02-13T00:00:00+09:00</updated><id>https://keisuke-yanagisawa.github.io/202202/validation_and_generalization_error</id><content type="html" xml:base="https://keisuke-yanagisawa.github.io/202202/validation_and_generalization_error/"><![CDATA[<p>機械学習では、train-valid-test分割 <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> という方法が良く用いられる。</p>

<p>訓練データとテストデータを分けるのは良くわかる（我々は良く「カンニング」と表現するが、これから予測したい対象を使って予測モデルを構築したらうまく予測できるのはほぼ自明である）。しかし、検証データを用いる必要性はちょっとわからないかもしれない。
この分割が何故必要なのか、考えてみようと思う。</p>

<h2 id="イメージを持つ代表選抜と本番での実力">イメージを持つ：代表選抜と本番での実力</h2>

<p>機械学習の議論をする前に、ちょっとイメージを持っておこう。</p>

<p>********</p>

<p>100m走の選手選抜を考えてみよう。とある高校で、以下のような実力伯仲な5人の100m走者がいるとする。彼らは調子によって <strong>\(\pm0.5\) 秒のタイムのぶれ</strong>がある。</p>

<table>
  <thead>
    <tr>
      <th>走者</th>
      <th style="text-align: right">平均タイム</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>山田</td>
      <td style="text-align: right">11.20 秒</td>
    </tr>
    <tr>
      <td>佐藤</td>
      <td style="text-align: right">11.21 秒</td>
    </tr>
    <tr>
      <td>田中</td>
      <td style="text-align: right">11.17 秒</td>
    </tr>
    <tr>
      <td>橋本</td>
      <td style="text-align: right">11.13 秒</td>
    </tr>
    <tr>
      <td>加藤</td>
      <td style="text-align: right">11.15 秒</td>
    </tr>
  </tbody>
</table>

<p>この5名から高校の代表選手を1名決めるために、タイム計測を行うことを考えてみよう。</p>

<p>********</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 毎回同じ結果が得られるように固定
</span>
<span class="c1"># 表の情報を記入
</span><span class="n">name</span> <span class="o">=</span> <span class="p">[</span><span class="s">"山田"</span><span class="p">,</span> <span class="s">"佐藤"</span><span class="p">,</span> <span class="s">"田中"</span><span class="p">,</span> <span class="s">"橋本"</span><span class="p">,</span> <span class="s">"加藤"</span><span class="p">]</span>
<span class="n">ave_time</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">11.20</span><span class="p">,</span> <span class="mf">11.21</span><span class="p">,</span> <span class="mf">11.17</span><span class="p">,</span> <span class="mf">11.13</span><span class="p">,</span> <span class="mf">11.15</span><span class="p">])</span>

<span class="c1"># +-0.5秒のぶれの設定（一様分布を仮定）
</span><span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> 

<span class="n">time</span> <span class="o">=</span> <span class="n">ave_time</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>        <span class="c1"># 小数点以下3桁までにする
</span><span class="k">print</span><span class="p">(</span><span class="s">"今回のタイム計測の記録"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</code></pre></div></div>

<p>その結果、加藤くんが11.074秒で最も早く、代表選手として選ばれた。</p>

<p>さて、翌週に地区大会があったとしよう。ここで加藤くんはどのような結果を出すだろうか？ <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ave_time</span> <span class="o">=</span> <span class="mf">11.15</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">ave_time</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"地区大会での加藤くんの記録"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
</code></pre></div></div>

<p>これを実行してみると、代表選手として選ばれた時のタイム（11.074秒）に比べて悪いタイム（11.199秒）となってしまった。これは偶然だろうか？「たまたま調子が悪かっただけなのでは？」という気もする。</p>

<p>しかし、地区大会は一発勝負だ。調子が悪かったのかもしれなくとも、2度以上試すことはできない。そこで、100この世界線があり、それぞれの世界線で加藤くんが地区大会で走ったと考えて <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> 、そのタイムの平均を取ってみよう。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ave_time</span> <span class="o">=</span> <span class="mf">11.15</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">ave_time</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">ave_time</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

<span class="n">ave_time</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">ave_time</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"地区大会での加藤くんの記録の平均"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ave_time</span><span class="p">)</span>
</code></pre></div></div>

<p>結果は平均11.123秒となり、依然代表選手として選ばれた時のタイム（11.074秒）と比べると遅い。
よくよく考えると、これはアタリマエの話である。100回、1000回と考えれば、加藤くんの記録の平均は11.150秒に収束するはずだ。この11.150秒という記録は、11.074秒に比べれば遅い。</p>

<p>大会に向けての調整をしない、という仮定を置いて考えているので現実世界とは異なる部分もあるが、<strong>選考の際に実力を十分に発揮できた人が選抜されやすい</strong>、ということが分かったと思う。</p>

<h2 id="機械学習と100m走">機械学習と100m走</h2>

<p>なぜこのような100m走の話をしたのだろうか。これは、機械学習のモデル選択と全く同じ状況だからである。</p>

<p>手元に5つの機械学習手法 + ハイパーパラメータの組があるとしよう。 <strong>本当は汎化誤差を知ることは不可能</strong>であり、全知全能な「天の声」視点に立っていると考えてほしいので、<strong>わざとカッコ書きにしている</strong>。</p>

<table>
  <thead>
    <tr>
      <th>機械学習手法 + ハイパーパラメータ</th>
      <th style="text-align: right">汎化誤差 (RMSE)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">DecisionTree(max_depth=20)</code></td>
      <td style="text-align: right">(2.958)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">DecisionTree(max_depth=5)</code></td>
      <td style="text-align: right">(2.921)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">RandomForest(n_estimators=100)</code></td>
      <td style="text-align: right">(2.863)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">RandomForest(n_estimators=200)</code></td>
      <td style="text-align: right">(2.857)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">RandomForest(n_estimators=500)</code></td>
      <td style="text-align: right">(2.854)</td>
    </tr>
  </tbody>
</table>

<p>それぞれのモデルは、性能評価に用いるデータセットの中身によって、 <strong>\(\pm0.2\) のRMSEのぶれが存在する</strong>としよう。</p>

<p>検証データで行いたいのは、この5つのモデルから、汎化誤差が最も良さそうなモデルを1つ選択することである。やってみよう。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 毎回同じ結果が得られるように固定
</span>
<span class="c1"># 表の情報を記入
</span><span class="n">name</span> <span class="o">=</span> <span class="p">[</span><span class="s">"DT20"</span><span class="p">,</span> <span class="s">"DT5"</span><span class="p">,</span> <span class="s">"RF100"</span><span class="p">,</span> <span class="s">"RF200"</span><span class="p">,</span> <span class="s">"RF500"</span><span class="p">]</span>
<span class="n">ave_gen_err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.958</span><span class="p">,</span> <span class="mf">2.921</span><span class="p">,</span> <span class="mf">2.863</span><span class="p">,</span> <span class="mf">2.857</span><span class="p">,</span> <span class="mf">2.854</span><span class="p">])</span>

<span class="c1"># +-0.2のぶれの設定（一様分布を仮定）
</span><span class="n">noise</span> <span class="o">=</span> <span class="mf">0.4</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.2</span> 

<span class="n">valid_err</span> <span class="o">=</span> <span class="n">ave_gen_err</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">valid_err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">valid_err</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>        <span class="c1"># 小数点以下3桁までにする
</span><span class="k">print</span><span class="p">(</span><span class="s">"検証データを用いたときのRMSE"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">valid_err</span><span class="p">)</span>
</code></pre></div></div>

<p>この結果、<code class="language-plaintext highlighter-rouge">RandomForest(n_estimators=500)</code> が RMSE=2.823 で最も良いモデルである、と選択される。</p>

<p>さて、このモデルを本番環境に適用したときの<strong>誤差の期待値（＝汎化誤差）を知りたい</strong>、と考えてみよう。<strong>モデル選択を行った際のRMSE値を使えばいいじゃないか、と思うかもしれないが、これは正しい推定値になっているのだろうか？</strong></p>

<p><strong>誤差の期待値</strong>とは、先ほどの例における「地区大会における平均タイム」と同じであるから、独立した試行を十分な回数行った場合の平均性能を見てみればよい。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ave_gen_err</span> <span class="o">=</span> <span class="mf">2.854</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.4</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.2</span> 
<span class="n">test_err</span> <span class="o">=</span> <span class="n">ave_gen_err</span> <span class="o">+</span> <span class="n">noise</span>
<span class="n">ave_test_err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_err</span><span class="p">)</span>
<span class="n">ave_test_err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">ave_test_err</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"誤差の期待値（汎化性能の期待値）"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ave_test_err</span><span class="p">)</span>
</code></pre></div></div>

<p>この結果、 RMSE=2.843 となり、やはりモデル選択を行った際のRMSE (2.823) の方が良い値となっている。</p>

<p>このように、<strong>モデル選択を行った際の誤差の値というのは、期待値よりも良くなってしまい、汎化性能を正しく推定できていない。</strong>以上のことから、モデル選択を行う検証データセットのみで汎化性能を評価することは良くなく、検証データとは別に、テストデータを準備して、<strong>テストデータをもとに汎化性能を評価する</strong>必要がある。これが、train-validではなくtrain-valid-test分割を行う必要がある原因である。</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>例えば、https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c に記述がある <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>ここでは、簡単のために、「加藤くんは校内選抜と地区大会で同じ能力を発揮する」と仮定している。 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>無茶苦茶な話だが…。 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><category term="データサイエンス・機械学習" /><category term="教師あり学習" /><category term="予測誤差" /><summary type="html"><![CDATA[機械学習では、train-valid-test分割 1 という方法が良く用いられる。 例えば、https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c に記述がある &#8617;]]></summary></entry><entry><title type="html">不均衡なデータ</title><link href="https://keisuke-yanagisawa.github.io/202202/imbalanced-data/" rel="alternate" type="text/html" title="不均衡なデータ" /><published>2022-02-09T00:00:00+09:00</published><updated>2022-02-09T00:00:00+09:00</updated><id>https://keisuke-yanagisawa.github.io/202202/imbalanced-data</id><content type="html" xml:base="https://keisuke-yanagisawa.github.io/202202/imbalanced-data/"><![CDATA[<p>Bioinformaticsの分野をやっていると、<strong>不均衡なデータ</strong>によく出くわすものである。
特に、正例 positive が少なく、負例 negative が多いケースが多い。
このような状態だと、何も考えずに構築したモデルは、いかなるデータが来ようとも負例として予測してしまうことすらある。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># 不均衡データ（1対50）を作成
</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="p">[</span><span class="mi">500</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">centers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">].</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"negative"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"positive"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://keisuke-yanagisawa.github.io/assets/img/posts/202202/2022-02-09-imbalanced-data-01.png" alt="データの散布図" /></p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># 予測モデルの構築
# （説明のためにgammaを下げて問題を誘発している）
</span><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">svc</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</code></pre></div></div>

<p>これを行うと、<code class="language-plaintext highlighter-rouge">[3, -1]</code> は<strong>負例である</strong>、という予測結果が出てくる。
しかし、これを先ほど示した図に載せるとどこになるだろうか。
以下のようになり、<strong>明らかに正例であるべき場所</strong>である。</p>

<p><img src="https://keisuke-yanagisawa.github.io/assets/img/posts/202202/2022-02-09-imbalanced-data-02.png" alt="不均衡データの学習" /></p>

<p>これは意図的に変数 \(\gamma\) を下げることで（モデルの複雑度を下げて）誘発しているが、単なる正解率に基づくハイパーパラメータ探索は<strong>いつのまにか</strong>この問題に入りこんでしまう事がある。注意しなければならない。</p>

<h5 id="関連参考文献順不同">関連参考文献（順不同）</h5>
<ul>
  <li>Alice Zheng, Amanda Casari 著、株式会社ホクソエム 訳『機械学習のための特徴量エンジニアリング』（オライリージャパン、2019年）
    <ul>
      <li>不均衡データに対して、ダウンサンプリングを行うことで不均衡を是正する方法を4.2.1節で説明している。</li>
    </ul>
  </li>
  <li>中山浩太郎 監修、塚本邦尊、山田典一、大澤文孝 著『東京大学のデータサイエンティスト育成講座』（マイナビ出版、2019年）
    <ul>
      <li>不均衡データに対する予測モデルの評価において、正解率を使うのではなくROC曲線のAUC (Area Under the Curve) を使うことを10-3-2-4節で述べている。</li>
    </ul>
  </li>
  <li>門脇大輔、阪田隆司、保坂桂佑、平松雄司 著『Kaggleで勝つデータ分析の技術』（技術評論社、2019年）
    <ul>
      <li>99.4%が負例であったKaggleのコンペについて2.6.5節で触れている。ここではROC曲線ではなくPR曲線のAUCを使う話をしている。</li>
    </ul>
  </li>
</ul>]]></content><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><category term="データサイエンス・機械学習" /><category term="教師あり学習" /><category term="データセット" /><summary type="html"><![CDATA[Bioinformaticsの分野をやっていると、不均衡なデータによく出くわすものである。 特に、正例 positive が少なく、負例 negative が多いケースが多い。 このような状態だと、何も考えずに構築したモデルは、いかなるデータが来ようとも負例として予測してしまうことすらある。]]></summary></entry><entry><title type="html">共溶媒分子動力学 (MSMD) 法における共溶媒セットの構築手法 EXPRORER</title><link href="https://keisuke-yanagisawa.github.io/research/exprorer" rel="alternate" type="text/html" title="共溶媒分子動力学 (MSMD) 法における共溶媒セットの構築手法 EXPRORER" /><published>2022-02-06T00:00:00+09:00</published><updated>2022-02-06T00:00:00+09:00</updated><id>https://keisuke-yanagisawa.github.io/research/exprorer</id><content type="html" xml:base="https://keisuke-yanagisawa.github.io/research/exprorer"><![CDATA[<p>2021年6月に <em>Journal of Chemical Information and Modeling</em> 誌に掲載された、
EXPRORER (EXtended PRObes set construction by REpresentative Retrieval) の話。</p>

<p><img src="https://keisuke-yanagisawa.github.io/assets/img/posts/202202/2022-02-06_01.png" alt="EXPRORER" /></p>

<h2 id="研究背景">研究背景</h2>

<p>共溶媒分子動力学 (mixed-solvent molecular dynamics; MSMD) 法は、
タンパク質を溶質、水分子と共溶媒分子を溶媒とした分子動力学 (molecular dynamics; MD) 法である。
共溶媒（プローブ分子）として、芳香環や疎水基、正負に帯電している分子などを用いることで、
水分子では観測できないタンパク質表面のホットスポットの発見や、
低分子結合部位の検出、低分子結合親和性の予測など、
薬剤開発の様々なステップで活用することが出来る。</p>

<p>既存の MSMD 手法である MixMD, SILCS, MDmix などは、結合親和性の評価精度改善に注力する一方、
どのような共溶媒を用いるか、のコンセンサスが取れていない。
また、分子構造は極めて多様であるが、その多様性に比べると余りにも少ないのが現状である。</p>

<h2 id="研究成果">研究成果</h2>

<p>このような問題に対して、薬剤分子に頻出する部分構造を共溶媒として切り出し、
これに対するMSMDシミュレーションを行うことで、
<strong>「網羅的」な共溶媒セットの構築を行う EXPRORER を開発した</strong><sup id="fnref:EXPRORER" role="doc-noteref"><a href="#fn:EXPRORER" class="footnote" rel="footnote">1</a></sup>。</p>

<p>前述のように、この手法は「セットの構築」が主要な目的ではあるが、
他方、MSMDシミュレーションのためのシミュレーション空間の構築や
MSMDシミュレーションの実施をフリーソフトウェアのみで完結する
仕組みを<a href="https://github.com/keisuke-yanagisawa/exprorer">github上で公開</a>している。</p>

<h2 id="雑談">（雑談）</h2>

<p>…作者本人もEXPRORERの立ち位置が、「MSMDシミュレーションツールそのもの」なのか迷う時があるが、
この手法はあくまで<strong>「共溶媒セットの構築」のための手法</strong>であることに注意したい。</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:EXPRORER" role="doc-endnote">
      <p><strong>Keisuke Yanagisawa</strong>, Yoshitaka Moriwaki, Tohru Terada, Kentaro Shimizu. “EXPRORER: Rational Cosolvent Set Construction Method for Cosolvent Molecular Dynamics Using Large-Scale Computation”, <em>Journal of Chemical Information and Modeling</em>, <strong>61</strong>: 2744-2753, 2021/06. DOI: <a href="https://doi.org/10.1021/acs.jcim.1c00134">10.1021/acs.jcim.1c00134</a> <a href="#fnref:EXPRORER" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><category term="研究成果" /><category term="共溶媒分子動力学法" /><category term="分子動力学法" /><category term="EXPRORER" /><summary type="html"><![CDATA[2021年6月に Journal of Chemical Information and Modeling 誌に掲載された、 EXPRORER (EXtended PRObes set construction by REpresentative Retrieval) の話。]]></summary></entry><entry><title type="html">内挿と外挿</title><link href="https://keisuke-yanagisawa.github.io/202202/interpolation_and_extrapolation/" rel="alternate" type="text/html" title="内挿と外挿" /><published>2022-02-02T00:00:00+09:00</published><updated>2022-02-02T00:00:00+09:00</updated><id>https://keisuke-yanagisawa.github.io/202202/interpolation_and_extrapolation</id><content type="html" xml:base="https://keisuke-yanagisawa.github.io/202202/interpolation_and_extrapolation/"><![CDATA[<p>機械学習モデルを構築する上で、
本来データが存在するはずなのにサンプリングできていない（データを取得できていない）空間があると、
その部分の予測精度は落ちてしまう。これについて少し触れてみたい。</p>

<h2 id="データの疎密と誤差の大小">データの疎密と誤差の大小</h2>

<p>とりあえず実験してみよう。ここでは、\(x\) が \([-5,5]\) の範囲における \(\cos x\) を使ってモデルを構築し、
\(x\) が \([-10,10]\) の範囲の予測を行ってみている。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># データセット作成
</span><span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">test_X</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">test_y</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">test_X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># 予測モデルの構築
</span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">()</span>
<span class="n">svr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># テストデータに対する予測結果の描画
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"train dataset"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"green"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_X</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"true"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_X</span><span class="p">,</span> <span class="n">svr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">"predicted"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>以下に示したような図が作成されたはずだ。
この図からわかるように、訓練データ（緑点）がある区間は予測誤差は小さい一方、
訓練データが無い区間（両端）は予測誤差が大きくなっている。</p>

<p><img src="https://keisuke-yanagisawa.github.io/assets/img/posts/202202/2022-02-02_01.png" alt="予測結果" /></p>

<p>冒頭に述べたように、<strong>訓練データに存在していない領域の予測精度は低下してしまう</strong>ことがわかる。</p>

<h2 id="内挿と外挿">内挿と外挿</h2>

<p>上記で示した例は外挿、すなわち、訓練データの外側（すなわち外挿 extrapolation）の予測を行った。
一方で、学習データの内側に穴があいてしまうこともあるかもしれない。これに対する予測は「内挿 interpolation」と言える。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># データセット作成
</span><span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span> 
  <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)]</span> 
<span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">test_X</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">test_y</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">test_X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># 予測モデルの構築
</span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">svr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># テストデータに対する予測結果の描画
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"train dataset"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"green"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_X</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"true"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_X</span><span class="p">,</span> <span class="n">svr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">"predicted"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper right"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>この結果を見てみると、データが中抜けしている（内挿領域である） \([-1, 1]\) の領域の予測精度はそこまで悪くなく、
一方で外挿領域である \((-\infty, -2]\) や \([2, \infty)\) では予測が大幅に間違っている。</p>

<p><img src="https://keisuke-yanagisawa.github.io/assets/img/posts/202202/2022-02-02_02.png" alt="予測結果" /></p>

<p>この結果は人間の感覚と合致している。訓練データの並びを見たとき、内挿区間をなめらかにつなごうとすれば自然と山を作る。
一方外挿区間は、この訓練データの並びが \(\cos x\) から来ているのか \(ax^2 + bx + c\) から来ているのかわからないので、
人によって異なる曲線を描くだろう。</p>

<p>なんにせよ、<strong>外挿は内挿に比べて、さらに予測精度が悪化する</strong>事があるので注意したい。</p>

<!-- ##### 参考文献
- 江崎貴裕『分析者のためのデータ解釈学入門　データの本質をとらえる技術』（ソシム、2020年） -->]]></content><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><category term="データサイエンス・機械学習" /><category term="教師あり学習" /><category term="予測誤差" /><summary type="html"><![CDATA[機械学習モデルを構築する上で、 本来データが存在するはずなのにサンプリングできていない（データを取得できていない）空間があると、 その部分の予測精度は落ちてしまう。これについて少し触れてみたい。]]></summary></entry><entry><title type="html">因子分析と主成分分析</title><link href="https://keisuke-yanagisawa.github.io/202201/factor-analysis-and-principal-component-analysis/" rel="alternate" type="text/html" title="因子分析と主成分分析" /><published>2022-01-30T09:00:00+09:00</published><updated>2022-01-30T09:00:00+09:00</updated><id>https://keisuke-yanagisawa.github.io/202201/factor-analysis-and-principal-component-analysis</id><content type="html" xml:base="https://keisuke-yanagisawa.github.io/202201/factor-analysis-and-principal-component-analysis/"><![CDATA[<p>因子分析と主成分分析は似通った手法のように見える。
しかし、実際には大きく異なる点がある。</p>

<ul>
  <li><strong>因子分析</strong>：人間が「こういう組み合わせが共通因子として存在するのではないか」と考えて因子負荷量を決める
    <ul>
      <li>人間が考えながら因子を作り出すので、解釈性の高い結果を作りだせる。他人への説明が容易。</li>
    </ul>
  </li>
  <li><strong>主成分分析</strong>：「データに基づいて共通因子（＝主成分）を探してみる」方法で、因子負荷量はデータから自動的に決まる
    <ul>
      <li>自動的に作成されるので、得られた因子負荷量から、その因子が何を意味しているのかを人間が検討する。新しい発見につながる可能性がある。</li>
    </ul>
  </li>
</ul>

<p>ようするに、目的が異なるのである。</p>

<h5 id="参考文献">参考文献</h5>
<ul>
  <li>江崎貴裕『分析者のためのデータ解釈学入門　データの本質をとらえる技術』（ソシム、2020年）</li>
</ul>]]></content><author><name>Keisuke Yanagisawa</name><email>yanagisawa@c.titech.ac.jp</email></author><category term="データサイエンス・機械学習" /><category term="因子分析" /><category term="主成分分析" /><category term="教師なし学習" /><summary type="html"><![CDATA[因子分析と主成分分析は似通った手法のように見える。 しかし、実際には大きく異なる点がある。]]></summary></entry></feed>